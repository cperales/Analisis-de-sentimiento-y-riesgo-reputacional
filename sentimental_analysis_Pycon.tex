 \documentclass{beamer}
% \usetheme{Berkeley}
  \usetheme{Pittsburgh}
% \usetheme{Warsaw}
 \usecolortheme{lily}
 \usepackage[latin1]{inputenc}
 \usepackage[T1]{fontenc}
 \usepackage[spanish]{babel}
 \usepackage{amsmath,amsthm}
 \usepackage{makeidx}
 \usepackage{pgf}
 \usepackage{graphicx}
 \usepackage{epstopdf}
 \title{¿Podemos predecir si Twitter hundirá un banco?}
 %  \title{\Huge ¿Podemos predecir si Twitter hundirá un banco?}
 \author{Carlos Perales González}
 \date{\includegraphics[width=6cm] {./Imagenes/nfq_solutions.png}}

% \logo{\includegraphics[width=2cm] {./Imagenes/nfq_solutions.png}}

 \newcommand{\1}[1]{\onslide*<#1>{#1}}
\usepackage{ragged2e}
\justifying

\AtBeginSection{ 
\begin{frame} 
  \frametitle{Índice}
  \tableofcontents[currentsection]
\end{frame}
}

%\AtBeginSubsection{ 
%\begin{frame}
%  \frametitle{Índice}
%  \tableofcontents[currentsection,currentsubsection]
%\end{frame}
%}

 \begin{document}

 \maketitle

\begin{frame}{Índice}
\tableofcontents
\end{frame}

\section{¿Puede Twitter hundir un banco?}

\begin{frame}{¿Puede Twitter hundir un banco?}
\begin{center}
	\textbf{¿Puede Twitter hundir un banco?}\newline
\end{center}

Realmente, no hay datos históricos de que haya ocurrido con anterioridad.\newline

Sin embargo, con la reciente crisis financiera, los reguladores (BCE, FED) están empezando a pedir más medidas de control sobre los bancos.

\end{frame}

\begin{frame}
La regulación está asociada al riesgo:

\begin{itemize}
	\item Riesgo de mercado
	\item Riesgo de crédito
	\item \ldots
\end{itemize}


En breve, la Autoridad Bancaria Europea (EBA) exigirá a los bancos una medida del riesgo reputacional.\\

\begin{center}
	Riesgo $\rightarrow$ posibilidad de pérdidas (ganancias, liquidez \ldots)
\end{center}

En este caso, a consecuencia del daño de de la perspectiva que la sociedad tenga de esta.
\end{frame}

% Hablar del poder de la comunicación.

% Preguntar retóricamente a la audiencia quién dejaría su dinero en Bankia, o quién compraría preferentes.


\begin{frame}{Causas y consecuencias}
	
	Hay una serie de directrices de la EBA sobre los temas más sensibles a la reputación.\newline
	
	\textbf{Causas de una mala reputación}
	
	\begin{itemize}
		\item Corrupción
		\item Mala gestión
		\item Política de empresa (negocios armamentísticos, deshaucios $\ldots$)
		\item $\ldots$
	\end{itemize}
	
	\textbf{Consecuencias}
	\begin{itemize}
		\item Retirada de efectivo
		\item No apertura de cuentas
		\item $\ldots$
	\end{itemize}
	
\end{frame}

\begin{frame}{Organización del trabajo}
\begin{enumerate}
	\item Recogida de tweets (\textit{tweemanager})
	\item Base de datos con tweets `positivos' y `negativos'
	\item Entrenamiento de un clasificador
	\item Clasificación a lo largo del tiempo $\rightarrow$ Indicador reputacional
\end{enumerate}
	% \justifying

	\textbf{Clasificador}: instrumento matemático que se sirve de un algoritmo estadístico con el fin de asignar una etiqueta clasificatoria. %\footcite{mitchell1997machine}.  T. Mitchell (1997), Machine Learning, McGraw Hill. ISBN 0-07-042807-7
	
\end{frame}

\section{Análisis de Sentimiento}

\subsection{Usos de este análisis}

\begin{frame}{Usos de este análisis}
		\textbf{Análisis de sentimiento}: determinación automatizada de la subjetividad, polaridad (`positivo', `negativo') y fuerza que tenga un texto.\newline % \footcite{brooke2009cross}.
	% Explicación de algo más que la definición
%	\textbf{Análisis de sentimiento}: determinanción automatizada de la subjetividad, polaridad (`positivo', `negativo') y fuerza que tenga un texto.\newline % \footcite{brooke2009cross}.
	En pocas palabras, clasifica en `bueno' y `malo'. Nos puede servir para ver cómo evolucionan las opiniones.\newline

	\begin{columns}
		\column{0.5\textwidth}
\begin{itemize}
	\item Análisis de mercado
	\item Inteligencia artificial
\end{itemize}
		\column{0.6\textwidth}
 	\includegraphics[width=0.6\textwidth]{./Imagenes/samsung1.png}
	\end{columns}


\end{frame}

\subsection{Análisis en español}

\begin{frame}{Análisis en español}
La mayoría de la bibliografía que se puede encontrar sobre el tema está en inglés. ¿Por qué?

% Imagen "English motherfucker do you speak it"
 \begin{figure}[H]
   \centering
 	\includegraphics[width=0.8\textwidth]{./Imagenes/english.png}
% 	\caption{Curva ROC del clasificador bayesiano ingenuo}
% 	\label{fig:ROCnb}
 \end{figure}
\end{frame}

\begin{frame}{Análisis en español}

¿Por qué hay más análisis de sentimiento en inglés, pese a ser el español una lengua bastante hablada?

\begin{itemize}
	\item Construcción gramatical más sencilla
	\item Menos formas verbales
	\item Muchos verbos regulares y lexemas sencillos
\end{itemize}

\begin{center}
	\textbf{El español es más difícil que el inglés}
\end{center}

\end{frame}

\begin{frame}{Análisis en español}
	Para un análisis en español hemos tenido que trabajar antes el texto.
	
	\begin{enumerate}
		\item Stopwords (artículos, preposiciones \ldots)
		\item Stemming (reducir una palabra a su raíz)
		\item Uso de n-gramas (secuencias de \textit{n} palabras)
	\end{enumerate}
	
	Inicialmente nos apoyamos en el paquete \textit{NLTK} para estos procesos, por la cantidad de reglas que involucraban.
\end{frame}

% Ejemplo de qué son bigamas y trigramas

%\begin{frame}{Análisis en español}
%	
%\end{frame}


%\section{Aplicación al riesgo reputacional}

\subsection{Entrenamiento específico para reputación}

\begin{frame}{Corpus}
	Para que el algoritmo clasificador funcione el entrenamiento tiene que ser el adecuado.\\
	

	\begin{center}
		Buen entrenamiento $\rightarrow$ Buen clasificador
	\end{center}
	
	El entrenamiento se ha conseguido escogiendo tweets que representen las directrices de la EBA sobre qué afecta a la reputación.\newline
	
	Nuestro corpus se ha obtenido mediante recogida de tweets, usando \textit{tweemanager}, buscando sobre entidades financieras.\newline
	
	\url{https://github.com/nfqsolutions/tweemanager}
\end{frame}

\section{Metodología de clasificación}

\begin{frame}{Estructura}

\begin{enumerate}
	\item Extracción del tweet en sus features
	\item Reglas de probabilidad para los features
	\item Composición de features en un clasificador
\end{enumerate}

\textbf{\textit{Features}}: propiedades de un fenómeno a estudiar. Sirven como variables.\newline

\begin{itemize}
\item Nuestras \textit{features} serán n-gramas del texto
\end{itemize}


\end{frame}

\subsection{Extracción de features}






\begin{frame}{Extracción de features}
	
	\begin{itemize}
		\item Se aplica \textit{stemming} y \textit{stopwords}
	\end{itemize}
	
	%\end{frame}
	%
	%\begin{frame}{Construcción de n-gramas}
	
	\begin{center}
		`CaixaBank, reconocida por su compromiso con la conciliación laboral y familiar'
	\end{center}
	
	`caixabank', `reconoc', `compromis', `conciliacion', `laboral', `famili', `caixabank reconoc', `reconoc por', `por su', `su compromis', `compromis con', `con la', `la conciliacion', `conciliacion laboral', `laboral y', `y famili', `caixabank reconoc por', `reconoc por su', `por su compromis', `su compromis con', `compromis con la', `con la conciliacion', `la conciliacion laboral', `conciliacion laboral y', `laboral y famili'\\
	
\end{frame}


\subsection{Estimación de probabilidades}



\begin{frame}{Laplace simple}
	
	La probabilidad de Laplace simple (LS) es puramente frecuentista
	
	\begin{equation}
	\label{ec:laplace}
	P(ngram|pos) = \frac{d}{N}
	\end{equation}
	
	
	Donde:
	\begin{description}
		\item $d$ es el nº de veces que aparece en positivo
		\item $N$ es el nº de veces total que aparece
	\end{description}
	
	
\end{frame}

\begin{frame}{Laplace suavizado (o adición suavizada)}
	
	La probabilidad de Laplace suavizada (AS) es una composición de la probabilidad de Laplace con la prob. uniforme
	
	\begin{equation}
	\label{ec:adsm}
	P(ngram|pos) = \frac{d + \alpha}{N + n_{cat} \alpha}
	\end{equation}
	
	
	Donde:
	\begin{description}
		\item  $\alpha$ es un factor de composición. Se ha escogido $0.5$
		\item  $n_{cat}$ es el nº de categorías (`positivo' y `negativo' $\rightarrow 2$)
	\end{description}
	
	
\end{frame}

\begin{frame}{Laplace simple vs suavizado}
	\begin{itemize}
		\item Ante variación de N y d, Laplace suavizado funciona mejor
		\item Con valores d y N altos, tiende a Laplace simple
		\item Laplace suavizado evita asignar valores extremos
	\end{itemize}
\end{frame}


\begin{frame}{Ejemplos}
	
	\begin{center}
		`CaixaBank impulsará el crédito entre los abogados de Castellón'
	\end{center}
	
	\begin{columns}
		\column{0.5\textwidth}
		`impuls' (LS) $\rightarrow 1.0$
		\column{0.5\textwidth}
		`impuls' (AS) $\rightarrow 0.75$ \newline
	\end{columns}
	
	
	
	\begin{columns}
		\column{0.5\textwidth}
		`credit' (LS) $\rightarrow 0.9167$
		\column{0.5\textwidth}
		`credit' (AS) $\rightarrow 0.8846$ \newline
	\end{columns}
	
	
	%	\begin{columns}
	%		\column{0.5\textwidth}
	%		`abog' (LS) $\rightarrow 0.9286$
	%		\column{0.5\textwidth}
	%		`abog' (AS) $\rightarrow 1.0$
	%	\end{columns}
	
\end{frame}

\subsection{Clasificadores}

\begin{frame}{Clasificadores}
	
	El tweet está formado por \textit{features}
	
	\begin{equation*}
	tweet \sim features
	\end{equation*}
	
	
	Para la clasificación usamos el teorema de Bayes
	
	\begin{equation}
	\label{ec:label_features}
	P(pos|features) = \frac{P(pos) P(features|pos)}{P(pos) P(features|pos) + P(neg) P(features|neg)}
	\end{equation}
	
	Se usa junto con la hipótesis de independencia
	
	\begin{equation}
	\label{ec:independencia}
	P(f_i  \cap f_j) = P (f_i | f_j) P(f_j) = P(f_i) P (f_j) \: \: \: \forall_{i, j} \: i \neq j
	\end{equation}
	
\end{frame}

\begin{frame}{Bayesiano ingenuo y nuestro indicador reputacional}
	
	¿Relación entre tweet y \textit{features}? El bayesiano ingenuo (\textit{Naive Bayesian} o NB):
	
	\begin{equation}
	\label{ec:tweet_features1}
	tweet = (feature_1, feature_2, \ldots , feature_n) = \bigcap_i f_i \equiv features
	\end{equation}
	
	
	¡Hipótesis! Cambiamos la concepción del elemento a clasificar
	
	\begin{equation}
	\label{ec:tweet_features2}
	tweet \sim \bigcup_i f_i \equiv features
	\end{equation}
	
	
\end{frame}

\begin{frame}{Comparación. Clasificador de manzanas}
	
	\begin{columns}
		\column{0.7\textwidth}
		Tenemos un objeto. ¿Será una manzana?
		\column{0.3\textwidth}
		\includegraphics[width=0.6\linewidth]{Imagenes/apple.png}
	\end{columns}
	
	
	%     \includegraphics[width=0.5]
	
	\begin{itemize}
		\item Rojo
		\item Redondo
		\item $\sim 7 \: cm$ de diámetro 
	\end{itemize}
	
	Bayesiano ingenuo (NB) $ \rightarrow $ Rojo y redondo y $\sim 7 \: cm$ de diámetro
	
	Nuestro indicador (IR) $ \rightarrow $ Promedio de variables.\newline
	
	NB presenta \textit{overfitting}. Tiende a puntuar con valores extremos.
	
	IR puntúa con valores intermedios. Es más conservador. 
	
\end{frame}



\section{Resultados}


\begin{frame}{¿Qué medimos? Acierto y ROC}
	
	Escogemos un set de validación para testear nuestros clasificadores.
	
	\begin{center}
		Set de validación $\rightarrow 10\%$ del tamaño del entrenamiento
	\end{center}
		
 Probamos cuántos es capaz de acertar (\textbf{tasa de aciertos}), junto con la curva ROC y el área bajo esta curva.
 
 	\begin{table}[H]
 		\centering
 		\begin{tabular}{l|l|l|}
 			\cline{2-3}
 			& Acierto (validación) & Acierto (entrenamiento) \\ \hline
 			\multicolumn{1}{|l|}{NB}    & 0.715              & 0.995                             \\ \hline
 			\multicolumn{1}{|l|}{IR} & 0.790              & 0.990                             \\ \hline
 		\end{tabular}
 	\end{table}
	
	% La curva ROC (\textit{Receiver Operating Characteristic} o Característica Operativa del Receptor) es una técnica para visualizar, organizar y seleccionar clasificadores basados en comparación de dos características operativas (la tasa de verdaderos positivos, TPR, y la tasa de falsos positivos) conforme el umbral discriminante cambia \cite{roc}. El área bajo esta curva representa la probabilidad de que un caso que el clasificador haya categorizado como positivo, efectivamente, sea realmente positivo 
\end{frame}

\subsection{Tasa de acierto}


\begin{frame}{Curva ROC}

	La \textbf{curva ROC} es una técnica para ver cómo varía la tasa de verdaderos positivos (TPR) y de falsos positivos (FPR) conforme el umbral discriminante cambia. \newline
	
	El \textbf{área bajo esta curva} representa la probabilidad de que un caso que el clasificador haya categorizado como positivo, efectivamente, sea realmente positivo \newline %\footcite{roc} \footcite{auc}	
	

\end{frame}

\subsection{Curva ROC}

\begin{frame}{Gráficas de la curva ROC. NB}
	\includegraphics[width=0.9\linewidth]{Imagenes/NB.png}
\end{frame}

\begin{frame}{Gráficas de la curva ROC. IR}
	\includegraphics[width=0.9\linewidth]{Imagenes/I.png}
\end{frame}

%\subsection{Indicador reputacional}
%
%\begin{frame}{Indicador reputacional}
%	\includegraphics[width=0.5\linewidth]{Imagenes/valoracion.png}
%	\includegraphics[width=0.5\linewidth]{Imagenes/positivos_negativos.png}
%\end{frame}

%\begin{frame}{Gráficas}
%
% \begin{figure}[H]
%   \centering
% 	\includegraphics[width=0.9\textwidth]{./Imagenes/NB.png}
% 	\caption{Curva ROC del clasificador bayesiano ingenuo}
% 	\label{fig:ROCnb}
% \end{figure}
%\end{frame}
%
%\begin{frame}{Gráficas}
%\begin{figure}[H]
%	\centering
%	\includegraphics[width=0.9\textwidth]{./Imagenes/I.png}
%	\caption{Curva ROC del clasificador de métrica reputacional}
%	\label{fig:ROCmetrica}
%\end{figure}
%
%\end{frame}

\section{Conclusiones}

\begin{frame}{Conclusiones}

\begin{itemize}
\item El clasificador NB tiene \textit{overfitting} que el clasificador IR no tiene.
\item Esto se debe, entre otras cosas, al uso de Laplace suavizado y a la hipótesis $tweet \sim \bigcup_i f_i$
\item La hipótesis de independencia es ingenua pero funciona
\item Los bigramas y trigramas ayudan al análisis en español
\end{itemize}

\begin{center}
	\textbf{Resultados parecidos $+$ ventajas de nuestro clasificador $\rightarrow$ $IR \geq NB$}
\end{center}


\end{frame}


\begin{frame}{Conclusiones}

\begin{itemize}
\item Prueba de una nueva concepción de objeto a clasificar 
\item Obtención de corpus específico para reputación
\item Solución técnica de un problema real
%\item Corpus dividido en secciones (noticias, economía, promoción y social/otros)
%\item Solo se han probado clasificadores supervisados
\item Desarrollo de la aplicación \textit{Qdos}
\end{itemize}

\begin{center}
	\includegraphics[width=0.6\linewidth]{Imagenes/qdos.png}
\end{center}

\end{frame}


\begin{frame}

\begin{center}
{\Huge Gracias por su atención!!\newline}

\includegraphics[width=0.4\linewidth]{Imagenes/sentiment-analysis-of-twitter-thanks.png}

\textbf{Agradecimientos}: Hugo Marrão y Rogelio Rodríguez
\end{center}

\end{frame}

 \end{document}